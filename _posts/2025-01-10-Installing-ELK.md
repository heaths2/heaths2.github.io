---
title: ELK Stack êµ¬ì„±
author: G.G
date: 2025-01-10 16:01:00 +0900
categories: [Blog, Provisioning]
tags: [Elasticsearch, Logstash, Kibana, Filebeat, Fortigate]
---

## ğŸ“˜ ê°œìš”
ELK Stack(Elasticsearch, Logstash, Kibana)ì€ ë¡œê·¸ ë°ì´í„°ë¥¼ ìˆ˜ì§‘, ì €ì¥, ë¶„ì„, ì‹œê°í™”í•˜ëŠ” ë° ìµœì í™”ëœ ì˜¤í”ˆ ì†ŒìŠ¤ ì†Œí”„íŠ¸ì›¨ì–´ ìŠ¤íƒì…ë‹ˆë‹¤. ë³¸ ë§¤ë‰´ì–¼ì€ ì—¬ëŸ¬ ëŒ€ì˜ FortiGate ë°©í™”ë²½ì—ì„œ ìƒì„±ë˜ëŠ” ë¡œê·¸ë¥¼ ì¤‘ì•™ ì§‘ì¤‘ì‹ìœ¼ë¡œ ê´€ë¦¬í•˜ê³  ì‹œê°í™”í•˜ê¸° ìœ„í•œ ELK Stack ì‹œìŠ¤í…œì˜ êµ¬ì„±ê³¼ ì„¤ì • ë°©ë²•ì„ ë‹¤ë£¹ë‹ˆë‹¤.

## ëª©ì 
1. FortiGate ë°©í™”ë²½ì—ì„œ ìƒì„±ë˜ëŠ” ë¡œê·¸ ë°ì´í„°ë¥¼ í•œ ê³³ì— ëª¨ì•„ ê´€ë¦¬.
2. ì‹¤ì‹œê°„ ë¡œê·¸ ë¶„ì„ ë° ê²€ìƒ‰ ê¸°ëŠ¥ ì œê³µ.
3. ì‚¬ìš©ì ì •ì˜ ëŒ€ì‹œë³´ë“œë¥¼ í†µí•œ ì§ê´€ì ì¸ ë°ì´í„° ì‹œê°í™”.
4. ë„¤íŠ¸ì›Œí¬ ë³´ì•ˆ ì´ë²¤íŠ¸ì˜ ì‹ ì†í•œ ëª¨ë‹ˆí„°ë§ ë° ëŒ€ì‘ ì²´ê³„ ê°•í™”.

## íŠ¹ì§•
1. ë°ì´í„° ìˆ˜ì§‘ ë° ë³€í™˜ (Logstash):
- ë‹¤ì–‘í•œ ì…ë ¥ í”ŒëŸ¬ê·¸ì¸ì„ ì‚¬ìš©í•´ FortiGate ì¥ë¹„ì—ì„œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘.
- ë°ì´í„° í•„í„°ë§ ë° ë³€í™˜ ê¸°ëŠ¥ì„ í†µí•´ ë¡œê·¸ í˜•ì‹ì„ í‘œì¤€í™”.
- í•„ìš”ì— ë”°ë¼ GeoIP, ë‚ ì§œ ë³€í™˜ ë“±ì˜ ì¶”ê°€ ì²˜ë¦¬ê°€ ê°€ëŠ¥.

2. ë°ì´í„° ì €ì¥ ë° ê²€ìƒ‰ (Elasticsearch):
- ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ êµ¬ì¡°í™”ëœ ë°©ì‹ìœ¼ë¡œ ì €ì¥.
- ë¹ ë¥¸ ê²€ìƒ‰ê³¼ ê³ ì„±ëŠ¥ ì¿¼ë¦¬ ì‹¤í–‰ ê°€ëŠ¥.
- ìŠ¤ëƒ…ìƒ· ë° í´ëŸ¬ìŠ¤í„° êµ¬ì„±ì„ í†µí•œ ê³ ê°€ìš©ì„±ê³¼ í™•ì¥ì„± ì§€ì›.

3. ë°ì´í„° ì‹œê°í™” (Kibana):
- ì‚¬ìš©ìê°€ ì§ì ‘ ì •ì˜í•  ìˆ˜ ìˆëŠ” ëŒ€ì‹œë³´ë“œ ì œê³µ.
- ì‹¤ì‹œê°„ìœ¼ë¡œ ë„¤íŠ¸ì›Œí¬ íŠ¸ë˜í”½, ë³´ì•ˆ ì´ë²¤íŠ¸ ë“±ì˜ ë°ì´í„°ë¥¼ ì‹œê°í™”.
- ë‹¤ì–‘í•œ ê·¸ë˜í”„ì™€ ì°¨íŠ¸ë¥¼ ì‚¬ìš©í•´ ë°ì´í„°ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ë¶„ì„.

4. í™•ì¥ì„± ë° ìœ ì—°ì„±:
- ìˆ˜ì§‘ ì¥ë¹„(FortiGate)ì˜ ê°œìˆ˜ ì¦ê°€ì— ë”°ë¼ ì†ì‰¬ìš´ í™•ì¥ ê°€ëŠ¥.
- ë‹¤ì–‘í•œ ë°ì´í„° ì†ŒìŠ¤ì™€ì˜ í†µí•© ì§€ì›.

5. ì¤‘ì•™ ì§‘ì¤‘í™”:
- ì—¬ëŸ¬ ëŒ€ì˜ FortiGate ì¥ë¹„ì—ì„œ ë°œìƒí•˜ëŠ” ë¡œê·¸ë¥¼ í•œ ê³³ìœ¼ë¡œ í†µí•©.
- ì¤‘ì•™ì—ì„œ ê´€ë¦¬í•¨ìœ¼ë¡œì¨ ë¡œê·¸ ë¶„ì‹¤ ë°©ì§€ ë° ë¶„ì„ íš¨ìœ¨ì„± ì¦ê°€.

6. ë³´ì•ˆ ë° ì ‘ê·¼ ì œì–´:
- Elasticsearchì™€ Kibanaì— ëŒ€í•œ ì—­í•  ê¸°ë°˜ ì•¡ì„¸ìŠ¤ ì œì–´(RBAC) ì ìš©.
- SSL/TLSë¥¼ í†µí•œ ë°ì´í„° ì „ì†¡ ì•”í˜¸í™”.

## í™˜ê²½ êµ¬ì„±

### JAVA JVM ì„¤ì¹˜

```bash
sudo apt update
sudo apt install -y openjdk-17-jdk
java -version
echo "
# Open JDK 17
JAVA_HOME=\"/usr/lib/jvm/java-17-openjdk-amd64/\"\
" >> /etc/environment
source /etc/environment
echo $JAVA_HOME
```

### Elasticsearch, Logstash, Kibana ì„¤ì¹˜

```bash
wget -qO - https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo gpg --dearmor -o /usr/share/keyrings/elasticsearch-keyring.gpg
sudo apt-get install apt-transport-https
echo "deb [signed-by=/usr/share/keyrings/elasticsearch-keyring.gpg] https://artifacts.elastic.co/packages/8.x/apt stable main" | sudo tee /etc/apt/sources.list.d/elastic-8.x.list
sudo apt-get update && sudo apt-get install -y elasticsearch logstash kibana
```

## Elasticsearch, Logstash, Kibana ì„¤ì¹˜ ë° ì„¤ì • ê°€ì´ë“œ

### Elasticsearch êµ¬ì„± ì„¤ì •
1. Elasticsearch í™˜ê²½ ë³€ìˆ˜ ì„¤ì •

```bash
echo "
# Elasticsearch
ES_HOME=/usr/share/elasticsearch
ES_PATH_CONF=/etc/elasticsearch" \
>> /etc/environment
source /etc/environment
echo $ES_HOME
echo $ES_PATH_CONF
```

2. Elasticsearch ì„¤ì • íŒŒì¼ ìˆ˜ì •

```bash
sed -i -e "s/#network.host:.*/network.host: 0.0.0.0/" \
       -e 's/#http.port: 9200/http.port: 9200/' \
       -e 's/path.data:.*/path.data: \/data\/elasticsearch/' \
       -e '/#bootstrap.memory_lock: true/ s/^#//' \
       -e "s/#cluster.name:.*/cluster.name: $(hostname -s)/" \
       -e "s/#node.name:.*/node.name: $(hostname -s)/" \
       -e '92s/enabled: true/enabled: false/' \
       -e '94s/enabled: true/enabled: false/' \
       -e '98s/enabled: true/enabled: false/' \
       -e '103s/enabled: true/enabled: false/' \
       -e '/#transport.host: 0.0.0.0/a\transport.port: 9300' /etc/elasticsearch/elasticsearch.yml
```

3. Elasticsearch ì„œë¹„ìŠ¤ ì„¤ì • ìˆ˜ì •

```bash
sed -i '/\[Install\]/i # LimitMEMLOCK\nLimitMEMLOCK=infinity\n' /usr/lib/systemd/system/elasticsearch.service
```

4. Elasticsearch JVM ë©”ëª¨ë¦¬ ì„¤ì •

```bash
sed -i -e 's/## -Xms4g/-Xms16g/' \
       -e 's/## -Xmx4g/-Xmx16g/' /etc/elasticsearch/jvm.options
```

5. Elasticsearch ì„œë¹„ìŠ¤ ì‹œì‘ ë° ìƒíƒœ í™•ì¸

```bash
sudo systemctl daemon-reload
sudo systemctl enable --now elasticsearch.service
curl -X GET http://localhost:9200/_cat/health?v
curl -X GET http://localhost:9200/_cluster/health?pretty
curl http://localhost:9200
```

```bash
{
  "name" : "nt-els01",
  "cluster_name" : "nt-els01",
  "cluster_uuid" : "Dqa7sGJIS7ivn96BiByPJQ",
  "version" : {
    "number" : "8.13.4",
    "build_flavor" : "default",
    "build_type" : "deb",
    "build_hash" : "da95df118650b55a500dcc181889ac35c6d8da7c",
    "build_date" : "2024-05-06T22:04:45.107454559Z",
    "build_snapshot" : false,
    "lucene_version" : "9.10.0",
    "minimum_wire_compatibility_version" : "7.17.0",
    "minimum_index_compatibility_version" : "7.0.0"
  },
  "tagline" : "You Know, for Search"
}
```

> - Elasticsearch í´ëŸ¬ìŠ¤í„° ì •ë³´ í™•ì¸ ì¶œë ¥ ì˜ˆì‹œ
{: .prompt-tip }

6. Elasticsearch í´ëŸ¬ìŠ¤í„° HA(ì„ íƒì‚¬í•­)

```yaml
# ======================== Elasticsearch Configuration =========================
#
# NOTE: Elasticsearch comes with reasonable defaults for most settings.
#       Before you set out to tweak and tune the configuration, make sure you
#       understand what are you trying to accomplish and the consequences.
#
# The primary way of configuring a node is via this file. This template lists
# the most important settings you may want to configure for a production cluster.
#
# Please consult the documentation for further information on configuration options:
# https://www.elastic.co/guide/en/elasticsearch/reference/index.html
#
# ---------------------------------- Cluster -----------------------------------
#
# Use a descriptive name for your cluster:
#
cluster.name: Network-ELS
#
# ------------------------------------ Node ------------------------------------
#
# Use a descriptive name for the node:
#
node.name: nt-els01
#
# Add custom attributes to the node:
#
#node.attr.rack: r1
#
# ----------------------------------- Paths ------------------------------------
#
# Path to directory where to store the data (separate multiple locations by comma):
#
path.data: /data/elasticsearch
#
# Path to log files:
#
path.logs: /var/log/elasticsearch
#
# ----------------------------------- Memory -----------------------------------
#
# Lock the memory on startup:
#
bootstrap.memory_lock: true
#
# Make sure that the heap size is set to about half the memory available
# on the system and that the owner of the process is allowed to use this
# limit.
#
# Elasticsearch performs poorly when the system is swapping the memory.
#
# ---------------------------------- Network -----------------------------------
#
# By default Elasticsearch is only accessible on localhost. Set a different
# address here to expose this node on the network:
#
network.host: 0.0.0.0
#
# By default Elasticsearch listens for HTTP traffic on the first free port it
# finds starting at 9200. Set a specific HTTP port here:
#
http.port: 9200
#
# For more information, consult the network module documentation.
#
# --------------------------------- Discovery ----------------------------------
#
# Pass an initial list of hosts to perform discovery when this node is started:
# The default list of hosts is ["127.0.0.1", "[::1]"]
#
discovery.seed_hosts: ["nt-els01", "nt-els02", "nt-els03"]
#
# Bootstrap the cluster using an initial set of master-eligible nodes:
#
cluster.initial_master_nodes: ["nt-els01", "nt-els02", "nt-els03"]
#
# For more information, consult the discovery and cluster formation module documentation.
#
# ---------------------------------- Various -----------------------------------
#
# Allow wildcard deletion of indices:
#
#action.destructive_requires_name: false

#----------------------- BEGIN SECURITY AUTO CONFIGURATION -----------------------
#
# The following settings, TLS certificates, and keys have been automatically      
# generated to configure Elasticsearch security features on 19-06-2024 06:23:22
#
# --------------------------------------------------------------------------------

# Optimizing resource management and stability of your Elasticsearch cluster
node.roles: ["data", "master", "ingest", "ml", "remote_cluster_client"]
indices.fielddata.cache.size: 80%
indices.breaker.fielddata.limit: 90%
indices.breaker.total.limit: 90%
indices.breaker.request.limit: 60%
indices.memory.index_buffer_size: 50%
indices.query.bool.max_clause_count: 2048

# Enable security features
xpack.security.enabled: false

xpack.security.enrollment.enabled: false

# Enable encryption for HTTP API client connections, such as Kibana, Logstash, and Agents
xpack.security.http.ssl:
  enabled: false
  keystore.path: certs/http.p12

# Enable encryption and mutual authentication between cluster nodes
xpack.security.transport.ssl:
  enabled: false
  verification_mode: certificate
  keystore.path: certs/transport.p12
  truststore.path: certs/transport.p12
# Create a new cluster with the current node only
# Additional nodes can still join the cluster later
cluster.initial_master_nodes: ["nt-els01", "nt-els02", "nt-els03"]

# Allow HTTP API connections from anywhere
# Connections are encrypted and require user authentication
http.host: 0.0.0.0

# Allow other nodes to join the cluster from anywhere
# Connections are encrypted and mutually authenticated
#transport.host: 0.0.0.0
transport.port: 9300

#----------------------- END SECURITY AUTO CONFIGURATION -------------------------
```
{: file='elasticsearch.yml'}

### Kibana êµ¬ì„± ì„¤ì •
1. Kibana í™˜ê²½ ë³€ìˆ˜ ì„¤ì •

```bash
echo "
# Elasticsearch
KIBANA_HOME=/usr/share/kibana
KIBANA_PATH_CONFIG=/etc/kibana" \
>> /etc/environment
source /etc/environment
echo $KIBANA_HOME
echo $KIBANA_PATH_CONFIG
```

2. Kibana ì„¤ì • íŒŒì¼ ìˆ˜ì •

```bash
sed -i -e '/#server.port: 5601/ s/^#//' \
       -e 's/#server.host:.*/server.host: "0.0.0.0"/' \
       -e "s/#server.name:.*/server.name: \"$(hostname -s)\"/" \
       -e 's/#i18n.locale: "en"/i18n.locale: "ko_KR"/' \
       -e '/#elasticsearch.hosts:/ s/^#//' /etc/kibana/kibana.yml
```

3. Kibana ì„œë¹„ìŠ¤ ì‹œì‘ ë° ìƒíƒœ í™•ì¸

```bash
sudo systemctl daemon-reload
sudo systemctl enable --now kibana.service
```

### Logstash FortiGate ë¡œê·¸ íŒŒì‹± ë° Elasticsearch ì—°ë™ ì„¤ì •
1. Logstash ì„¤ì • íŒŒì¼ ìƒì„±

```bash
cat <<EOF > /etc/logstash/conf.d/fortigate.conf
input {
  beats {
    port => 5044
  }
}

filter {
  grok {
    match => {
      "message" => "\[%{TIMESTAMP_ISO8601:timestamp}\] %{DATA:device} >> (?:date=%{YEAR:year}-%{MONTHNUM:month}-%{MONTHDAY:day} )?(?:time=%{HOUR:hour}:%{MINUTE:minute}:%{SECOND:second} )?(?:devname=\"%{DATA:devname}\" )?(?:devid=\"%{DATA:devid}\" )?(?:eventtime=%{NUMBER:eventtime} )?(?:tz=\"%{DATA:tz}\" )?(?:logid=\"%{DATA:logid}\" )?(?:type=\"%{DATA:type}\" )?(?:subtype=\"%{DATA:subtype}\" )?(?:level=\"%{DATA:level}\" )?(?:vd=\"%{DATA:vd}\" )?(?:srcip=%{IP:srcip} )?(?:srcport=%{NUMBER:srcport} )?(?:srcintf=\"%{DATA:srcintf}\" )?(?:srcintfrole=\"%{DATA:srcintfrole}\" )?(?:dstip=%{IP:dstip} )?(?:dstport=%{NUMBER:dstport} )?(?:dstintf=\"%{DATA:dstintf}\" )?(?:dstintfrole=\"%{DATA:dstintfrole}\" )?(?:srccountry=\"%{DATA:srccountry}\" )?(?:dstcountry=\"%{DATA:dstcountry}\" )?(?:sessionid=%{NUMBER:sessionid} )?(?:proto=%{NUMBER:proto} )?(?:action=\"%{DATA:action}\" )?(?:policyid=%{NUMBER:policyid} )?(?:policytype=\"%{DATA:policytype}\" )?(?:poluuid=\"%{UUID:poluuid}\" )?(?:service=\"%{DATA:service}\" )?(?:trandisp=\"%{DATA:trandisp}\" )?(?:transip=%{IP:transip} )?(?:transport=%{NUMBER:transport} )?(?:duration=%{NUMBER:duration} )?(?:sentbyte=%{NUMBER:sentbyte} )?(?:rcvdbyte=%{NUMBER:rcvdbyte} )?(?:sentpkt=%{NUMBER:sentpkt} )?(?:rcvdpkt=%{NUMBER:rcvdpkt} )?(?:appcat=\"%{DATA:appcat}\" )?(?:mastersrcmac=\"%{MAC:mastersrcmac}\" )?(?:srcmac=\"%{MAC:srcmac}\" )?(?:srcserver=%{NUMBER:srcserver})?"
    }
  }

  # prune í•„í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¶ˆí•„ìš”í•œ í•„ë“œ ì œê±°
  prune {
    whitelist_names => [ "timestamp", "device", "devname", "devid", "eventtime", "tz", "logid", "type", "subtype", "level", "vd", "srcip", "srcport", "srcintf", "srcintfrole", "dstip", "dstport", "dstintf", "dstintfrole", "srccountry", "dstcountry", "sessionid", "proto", "action", "policyid", "policytype", "poluuid", "service", "trandisp", "transip", "transport", "duration", "sentbyte", "rcvdbyte", "sentpkt", "rcvdpkt", "appcat", "mastersrcmac", "srcmac", "srcserver" ]
  }

  # mutate í•„í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ íŠ¹ì • í•„ë“œ ì œê±°
  mutate {
    remove_field => [ "event.original", "message" ]  # í•„ìš” ì—†ëŠ” í•„ë“œ ì œê±°
  }
}

output {
  elasticsearch {
    hosts => ["localhost:9200"]
    index => "fortigate-logs-%{+YYYY.MM.dd}"
  }
#  stdout { codec => rubydebug }
}
EOF
```
{: file='fortigate.conf'}

2. Logstash ì„¤ì • í…ŒìŠ¤íŠ¸ ë° ìë™ ì¬ë¡œë“œ

```bash
/usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/fortigate.conf --config.test_and_exit
/usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/fortigate.conf --config.reload.automatic
```

## Filebeat ì„¤ì¹˜ ë° êµ¬ì„± TOC
FortiGate ë¡œê·¸ ìˆ˜ì§‘ì„œë²„ì—ì„œ ì§„í–‰.

1. Filebeat ì„¤ì¹˜

```bash
echo "deb https://artifacts.elastic.co/packages/oss-8.x/apt stable main" | sudo tee -a /etc/apt/sources.list.d/elastic-8.x.list
sudo apt-get update && sudo apt-get install filebeat
```

2. Filebeat ì…ë ¥ í™œì„±í™”

```bash
sed -i -e 's/enabled: false/enabled: true/' \
           /etc/filebeat/filebeat.yml
```

3. `/etc/filebeat/filebeat.yml`{: .filepath} Filebeat êµ¬ì„± íŒŒì¼ ìƒì„±

```yaml
###################### Filebeat Configuration Example #########################

# This file is an example configuration file highlighting only the most common
# options. The filebeat.reference.yml file from the same directory contains all the
# supported options with more comments. You can use it as a reference.
#
# You can find the full configuration reference here:
# https://www.elastic.co/guide/en/beats/filebeat/index.html

# For more available modules and options, please see the filebeat.reference.yml sample
# configuration file.

# ============================== Filebeat inputs ===============================

filebeat.inputs:

# Each - is an input. Most options can be set at the input level, so
# you can use different inputs for various configurations.
# Below are the input-specific configurations.

# filestream is an input for collecting log messages from files.
- type: filestream

  # Unique ID among all inputs, an ID is required.
  #  id: my-filestream-id

  # Change to true to enable this input configuration.
  enabled: true

  # Paths that should be crawled and fetched. Glob based paths.
  paths:
    #- /var/log/*.log
    #- c:\programdata\elasticsearch\logs\*
    - /data/log/fg-100e/syslog
    - /data/log/fg-100f/syslog
    - /data/log/fg-200e/syslog
    - /data/log/fg-300d/syslog
    - /data/log/fg-400f/syslog
    - /data/log/fg-60d/syslog
    - /data/log/fg-60e/syslog

  fields:
    service: fortigate


  # Exclude lines. A list of regular expressions to match. It drops the lines that are
  # matching any regular expression from the list.
  # Line filtering happens after the parsers pipeline. If you would like to filter lines
  # before parsers, use include_message parser.
  #exclude_lines: ['^DBG']

  # Include lines. A list of regular expressions to match. It exports the lines that are
  # matching any regular expression from the list.
  # Line filtering happens after the parsers pipeline. If you would like to filter lines
  # before parsers, use include_message parser.
  #include_lines: ['^ERR', '^WARN']

  # Exclude files. A list of regular expressions to match. Filebeat drops the files that
  # are matching any regular expression from the list. By default, no files are dropped.
  #prospector.scanner.exclude_files: ['.gz$']

  # Optional additional fields. These fields can be freely picked
  # to add additional information to the crawled log files for filtering
  #fields:
  #  level: debug
  #  review: 1

# ============================== Filebeat modules ==============================

filebeat.config.modules:
  # Glob pattern for configuration loading
  path: ${path.config}/modules.d/*.yml

  # Set to true to enable config reloading
  reload.enabled: false

  # Period on which files under path should be checked for changes
  #reload.period: 10s

# ======================= Elasticsearch template setting =======================

setup.template.settings:
  index.number_of_shards: 1
  #index.codec: best_compression
  #_source.enabled: false


# ================================== General ===================================

# The name of the shipper that publishes the network data. It can be used to group
# all the transactions sent by a single shipper in the web interface.
#name:

# The tags of the shipper are included in their field with each
# transaction published.
#tags: ["service-X", "web-tier"]

# Optional fields that you can specify to add additional information to the
# output.
#fields:
#  env: staging

# ================================= Dashboards =================================
# These settings control loading the sample dashboards to the Kibana index. Loading
# the dashboards is disabled by default and can be enabled either by setting the
# options here or by using the `setup` command.
#setup.dashboards.enabled: false

# The URL from where to download the dashboard archive. By default, this URL
# has a value that is computed based on the Beat name and version. For released
# versions, this URL points to the dashboard archive on the artifacts.elastic.co
# website.
#setup.dashboards.url:

# =================================== Kibana ===================================

# Starting with Beats version 6.0.0, the dashboards are loaded via the Kibana API.
# This requires a Kibana endpoint configuration.
setup.kibana:

  # Kibana Host
  # Scheme and port can be left out and will be set to the default (http and 5601)
  # In case you specify and additional path, the scheme is required: http://localhost:5601/path
  # IPv6 addresses should always be defined as: https://[2001:db8::1]:5601
  #host: "localhost:5601"

  # Kibana Space ID
  # ID of the Kibana Space into which the dashboards should be loaded. By default,
  # the Default Space will be used.
  #space.id:

# =============================== Elastic Cloud ================================

# These settings simplify using Filebeat with the Elastic Cloud (https://cloud.elastic.co/).

# The cloud.id setting overwrites the `output.elasticsearch.hosts` and
# `setup.kibana.host` options.
# You can find the `cloud.id` in the Elastic Cloud web UI.
#cloud.id:

# The cloud.auth setting overwrites the `output.elasticsearch.username` and
# `output.elasticsearch.password` settings. The format is `<user>:<pass>`.
#cloud.auth:

# ================================== Outputs ===================================

# Configure what output to use when sending the data collected by the beat.

# ---------------------------- Elasticsearch Output ----------------------------
#output.elasticsearch:
  # Array of hosts to connect to.
#  hosts: ["localhost:9200"]

  # Performance preset - one of "balanced", "throughput", "scale",
  # "latency", or "custom".
#  preset: balanced

  # Protocol - either `http` (default) or `https`.
  #protocol: "https"

  # Authentication credentials - either API key or username/password.
  #api_key: "id:api_key"
  #username: "elastic"
  #password: "changeme"

# ------------------------------ Logstash Output -------------------------------
output.logstash:
  # The Logstash hosts
  hosts: ["10.1.10.11:5044"]

  # Optional SSL. By default is off.
  # List of root certificates for HTTPS server verifications
  #ssl.certificate_authorities: ["/etc/pki/root/ca.pem"]

  # Certificate for SSL client authentication
  #ssl.certificate: "/etc/pki/client/cert.pem"

  # Client Certificate Key
  #ssl.key: "/etc/pki/client/cert.key"

# ================================= Processors =================================
processors:
  - add_host_metadata:
      when.not.contains.tags: forwarded
  - add_cloud_metadata: ~
  - add_docker_metadata: ~
  - add_kubernetes_metadata: ~

    #output.console.pretty: true

# ================================== Logging ===================================

# Sets log level. The default log level is info.
# Available log levels are: error, warning, info, debug
#logging.level: debug

# At debug level, you can selectively enable logging only for some components.
# To enable all selectors, use ["*"]. Examples of other selectors are "beat",
# "publisher", "service".
#logging.selectors: ["*"]

# ============================= X-Pack Monitoring ==============================
# Filebeat can export internal metrics to a central Elasticsearch monitoring
# cluster.  This requires xpack monitoring to be enabled in Elasticsearch.  The
# reporting is disabled by default.

# Set to true to enable the monitoring reporter.
#monitoring.enabled: false

# Sets the UUID of the Elasticsearch cluster under which monitoring data for this
# Filebeat instance will appear in the Stack Monitoring UI. If output.elasticsearch
# is enabled, the UUID is derived from the Elasticsearch cluster referenced by output.elasticsearch.
#monitoring.cluster_uuid:

# Uncomment to send the metrics to Elasticsearch. Most settings from the
# Elasticsearch outputs are accepted here as well.
# Note that the settings should point to your Elasticsearch *monitoring* cluster.
# Any setting that is not set is automatically inherited from the Elasticsearch
# output configuration, so if you have the Elasticsearch output configured such
# that it is pointing to your Elasticsearch monitoring cluster, you can simply
# uncomment the following line.
#monitoring.elasticsearch:

# ============================== Instrumentation ===============================

# Instrumentation support for the filebeat.
#instrumentation:
    # Set to true to enable instrumentation of filebeat.
    #enabled: false

    # Environment in which filebeat is running on (eg: staging, production, etc.)
    #environment: ""

    # APM Server hosts to report instrumentation results to.
    #hosts:
    #  - http://localhost:8200

    # API Key for the APM Server(s).
    # If api_key is set then secret_token will be ignored.
    #api_key:

    # Secret token for the APM Server(s).
    #secret_token:


# ================================= Migration ==================================

# This allows to enable 6.7 migration aliases
#migration.6_to_7.enabled: true
logging.level: info
logging.to_files: true
logging.files:
  path: /var/log/filebeat/filebeat.log
  name: filebeat
  keepfiles: 7
  permissions: 0640
```
{: file='filebeat.yml'}

4. Filebeat í…ŒìŠ¤íŠ¸

```bash
filebeat test config
```

5. Filebeat ì‹¤í–‰

```bash
sudo systemctl enable filebeat
sudo systemctl start filebeat
```

## íŠœë‹
íŠœë‹ëœ ë§¤í•‘ ì„¤ì •ì€ ë¡œê·¸ ë°ì´í„°ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ê³ , ê²€ìƒ‰ ë° ì§‘ê³„ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ë° ì¤‘ì ì„ ë‘¡ë‹ˆë‹¤. ì•„ë˜ëŠ” FortiGate ë¡œê·¸ ë§¤í•‘ì„ íŠœë‹í•˜ëŠ” ë°©ë²•ê³¼ ì¶œë ¥ ì˜ˆì‹œì…ë‹ˆë‹¤.

### íŠœë‹ ëª©í‘œ
1. í•„ë“œ ìë£Œí˜• ìµœì í™”: text, keyword, ip, long, date ë“±ì„ ì ì ˆíˆ ì‚¬ìš©.
2. ë¶ˆí•„ìš”í•œ í•„ë“œ ì œì™¸: ë¡œê·¸ì—ì„œ ìì£¼ ì‚¬ìš©ë˜ì§€ ì•ŠëŠ” í•„ë“œëŠ” ì œê±°.
3. ë™ì  ë§¤í•‘ ì œí•œ: ë™ì  í•„ë“œ ìƒì„± ë°©ì§€ë¡œ ë¶ˆí•„ìš”í•œ ë¦¬ì†ŒìŠ¤ ì‚¬ìš© ë°©ì§€.

### ë§¤í•‘ íŠœë‹ ì„¤ì •

```bash
PUT /fortigate-logs-template
{
  "index_patterns": ["fortigate-logs-*"],
  "settings": {
    "number_of_shards": 1,
    "number_of_replicas": 1
  },
  "mappings": {
    "properties": {
      "@timestamp": { "type": "date" },
      "action": { "type": "keyword" },
      "appcat": { "type": "keyword" },
      "device": { "type": "keyword" },
      "devid": { "type": "keyword" },
      "devname": { "type": "keyword" },
      "dstcountry": { "type": "keyword" },
      "dstintf": { "type": "keyword" },
      "dstintfrole": { "type": "keyword" },
      "dstip": { "type": "ip" },
      "dstport": { "type": "integer" },
      "duration": { "type": "long" },
      "eventtime": { "type": "date" },
      "level": { "type": "keyword" },
      "logid": { "type": "keyword" },
      "mastersrcmac": { "type": "keyword" },
      "policyid": { "type": "long" },
      "policytype": { "type": "keyword" },
      "poluuid": { "type": "keyword" },
      "proto": { "type": "keyword" },
      "rcvdbyte": { "type": "long" },
      "rcvdpkt": { "type": "long" },
      "sentbyte": { "type": "long" },
      "sentpkt": { "type": "long" },
      "service": { "type": "keyword" },
      "sessionid": { "type": "keyword" },
      "srccountry": { "type": "keyword" },
      "srcintf": { "type": "keyword" },
      "srcintfrole": { "type": "keyword" },
      "srcip": { "type": "ip" },
      "srcmac": { "type": "keyword" },
      "srcport": { "type": "integer" },
      "subtype": { "type": "keyword" },
      "trandisp": { "type": "keyword" },
      "transip": { "type": "ip" },
      "transport": { "type": "integer" },
      "type": { "type": "keyword" },
      "tz": { "type": "keyword" },
      "vd": { "type": "keyword" }
    }
  }
}
```

3. íŠœë‹ëœ ë§¤í•‘ ì¶œë ¥ ì˜ˆì‹œ

```bash
{
  "fortigate-logs-2025.01.10" : {
    "mappings" : {
      "properties" : {
        "@timestamp" : {
          "type" : "date"
        },
        "action" : {
          "type" : "keyword"
        },
        "appcat" : {
          "type" : "keyword"
        },
        "device" : {
          "type" : "keyword"
        },
        "devid" : {
          "type" : "keyword"
        },
        "devname" : {
          "type" : "text"
        },
        "dstcountry" : {
          "type" : "text"
        },
        "dstintf" : {
          "type" : "text"
        },
        "dstintfrole" : {
          "type" : "keyword"
        },
        "dstip" : {
          "type" : "text"
        },
        "dstport" : {
          "type" : "long"
        },
        "duration" : {
          "type" : "keyword"
        },
        "eventtime" : {
          "type" : "keyword"
        },
        "level" : {
          "type" : "keyword"
        },
        "logid" : {
          "type" : "keyword"
        },
        "mastersrcmac" : {
          "type" : "keyword"
        },
        "policyid" : {
          "type" : "long"
        },
        "policytype" : {
          "type" : "keyword"
        },
        "poluuid" : {
          "type" : "keyword"
        },
        "proto" : {
          "type" : "keyword"
        },
        "rcvdbyte" : {
          "type" : "long"
        },
        "rcvdpkt" : {
          "type" : "keyword"
        },
        "sentbyte" : {
          "type" : "long"
        },
        "sentpkt" : {
          "type" : "keyword"
        },
        "service" : {
          "type" : "text"
        },
        "sessionid" : {
          "type" : "keyword"
        },
        "srccountry" : {
          "type" : "text"
        },
        "srcintf" : {
          "type" : "text"
        },
        "srcintfrole" : {
          "type" : "keyword"
        },
        "srcip" : {
          "type" : "text"
        },
        "srcmac" : {
          "type" : "keyword"
        },
        "srcport" : {
          "type" : "long"
        },
        "srcserver" : {
          "type" : "keyword"
        },
        "subtype" : {
          "type" : "keyword"
        },
        "timestamp" : {
          "type" : "text"
        },
        "trandisp" : {
          "type" : "keyword"
        },
        "transip" : {
          "type" : "text"
        },
        "transport" : {
          "type" : "long"
        },
        "type" : {
          "type" : "keyword"
        },
        "tz" : {
          "type" : "text"
        },
        "vd" : {
          "type" : "text"
        }
      }
    }
  }
}
```

> - íŠœë‹ëœ ë§¤í•‘ ì¶œë ¥ ì˜ˆì‹œ
{: .prompt-tip }

### ì£¼ìš” ë³€ê²½ ì‚¬í•­
1. í•„ë“œ ìë£Œí˜• ìµœì í™”:
- srcip, dstip, transip â†’ ip ìë£Œí˜•.
- dstport, srcport, transport â†’ integer.
- rcvdbyte, sentbyte, duration â†’ long.
- devname, dstcountry â†’ keyword (í…ìŠ¤íŠ¸ ë¶„ì„ì´ í•„ìš”í•˜ì§€ ì•ŠìŒ).
2. ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” í•„ë“œ ì œê±°:
- í•„ìš”í•˜ì§€ ì•Šì€ í•„ë“œëŠ” ë§¤í•‘ì—ì„œ ì œê±°.
3. ì¼ê´€ì„± ìœ ì§€:
- ë™ì¼í•œ ë°ì´í„° ìœ í˜•ì€ ë™ì¼í•œ ìë£Œí˜•ìœ¼ë¡œ í†µí•©.


### í…œí”Œë¦¿ ì ìš©
1. í…œí”Œë¦¿ ì ìš©

```bash
curl -X PUT "http://localhost:9200/_template/fortigate-logs-template" -H 'Content-Type: application/json' -d '
PUT /fortigate-logs-template
{
  "index_patterns": ["fortigate-logs-*"],
  "settings": {
    "number_of_shards": 1,
    "number_of_replicas": 1
  },
  "mappings": {
    "properties": {
      "@timestamp": { "type": "date" },
      "action": { "type": "keyword" },
      "appcat": { "type": "keyword" },
      "device": { "type": "keyword" },
      "devid": { "type": "keyword" },
      "devname": { "type": "keyword" },
      "dstcountry": { "type": "keyword" },
      "dstintf": { "type": "keyword" },
      "dstintfrole": { "type": "keyword" },
      "dstip": { "type": "ip" },
      "dstport": { "type": "integer" },
      "duration": { "type": "long" },
      "eventtime": { "type": "date" },
      "level": { "type": "keyword" },
      "logid": { "type": "keyword" },
      "mastersrcmac": { "type": "keyword" },
      "policyid": { "type": "long" },
      "policytype": { "type": "keyword" },
      "poluuid": { "type": "keyword" },
      "proto": { "type": "keyword" },
      "rcvdbyte": { "type": "long" },
      "rcvdpkt": { "type": "long" },
      "sentbyte": { "type": "long" },
      "sentpkt": { "type": "long" },
      "service": { "type": "keyword" },
      "sessionid": { "type": "keyword" },
      "srccountry": { "type": "keyword" },
      "srcintf": { "type": "keyword" },
      "srcintfrole": { "type": "keyword" },
      "srcip": { "type": "ip" },
      "srcmac": { "type": "keyword" },
      "srcport": { "type": "integer" },
      "subtype": { "type": "keyword" },
      "trandisp": { "type": "keyword" },
      "transip": { "type": "ip" },
      "transport": { "type": "integer" },
      "type": { "type": "keyword" },
      "tz": { "type": "keyword" },
      "vd": { "type": "keyword" }
    }
  }
}'
```

2. ìƒˆë¡œìš´ ì¸ë±ìŠ¤ ìƒì„±

```bash
curl -X PUT "http://localhost:9200/fortigate-logs-2025.01.10"
```

3. ê¸°ì¡´ ë°ì´í„° ì¬ìƒ‰ì¸(ì˜µì…˜: í•„ìš” ì‹œ)

```bash
curl -X POST "http://localhost:9200/_reindex" -H 'Content-Type: application/json' -d '
{
  "source": { "index": "fortigate-logs-old" },
  "dest": { "index": "fortigate-logs-new" }
}'
```

### ìµœì¢… í™•ì¸
1. í…œí”Œë¦¿ ì¡°íšŒ

```bash
curl -X GET "http://localhost:9200/_template/fortigate-logs-template?pretty"
```

2. ì¸ë±ìŠ¤ ë§¤í•‘ í™•ì¸

```bash
curl -X GET "http://localhost:9200/fortigate-logs-2025.01.10/_mapping?pretty"
```

3. ì¬ìƒ‰ì¸ ìƒíƒœ í™•ì¸

```bash
curl -X GET "http://localhost:9200/_tasks?pretty"
```

## ì°¸ì¡°
> - [JVM ë²„ì „ í˜¸í™˜](https://www.elastic.co/kr/support/matrix#matrix_jvm)
> - [logstash ê³µì‹ë¬¸ì„œ](https://www.elastic.co/guide/en/beats/filebeat/current/logstash-output.html)
> - [filebeat Processors ê³µì‹ë¬¸ì„œ](https://www.elastic.co/guide/en/beats/filebeat/current/filtering-and-enhancing-data.html)
> - [filebeat Logging ê³µì‹ë¬¸ì„œ](https://www.elastic.co/guide/en/beats/filebeat/current/configuration-logging.html)

```bash
â”œâ”€â”€ .env
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ filebeat.yml
â”œâ”€â”€ logstash.conf
â””â”€â”€ metricbeat.yml

sudo setenforce 0
sysctl -w vm.max_map_count=262144
```

```bash
# Project namespace (defaults to the current folder name if not set)
#COMPOSE_PROJECT_NAME=myproject

# Password for the 'elastic' user (at least 6 characters)
ELASTIC_USER=elastic
ELASTIC_PASSWORD=changeme

# Password for the 'kibana_system' user (at least 6 characters)
KIBANA_PASSWORD=changeme

# Version of Elastic products
STACK_VERSION=8.12.2

# Set the cluster name
CLUSTER_NAME=docker-cluster

# Set to 'basic' or 'trial' to automatically start the 30-day trial
LICENSE=basic
#LICENSE=trial

# Port to expose Elasticsearch HTTP API to the host
ES_PORT=9200

# Port to expose Kibana to the host
KIBANA_PORT=5601

# Increase or decrease based on the available host memory (in bytes)
ES_MEM_LIMIT=3221225472
KB_MEM_LIMIT=1073741824
LS_MEM_LIMIT=1073741824

# SAMPLE Predefined Key only to be used in POC environments
ENCRYPTION_KEY=c34d38b3a14956121ff2170e5030b471551370178f43e5626eec58b04a30fae2

#ES_DISCOVERY_HOSTS=es01,es02,es03
#ES_MASTER_NODES=es01,es02,es03
ES_JAVA_OPTS="-Xms2048m -Xmx2048m"
```

```yaml
# logstash.conf
input {
  beats {
    port => 5044
    ssl => true
    ssl_certificate_authorities => ["/usr/share/logstash/config/certs/ca/ca.crt"]
    ssl_certificate => "/usr/share/logstash/config/certs/logstash/logstash.crt" # Logstash ìì²´ ì¸ì¦ì„œ (Beatsì™€ì˜ SSL í†µì‹ ìš©)
    ssl_key => "/usr/share/logstash/config/certs/logstash/logstash.key" # Logstash ìì²´ í‚¤
    ssl_verify_mode => "peer"
  }
}

filter {
  # í•„ìš”ì— ë”°ë¼ ë°ì´í„° í•„í„°ë§ ë° ë³€í™˜ ë¡œì§ ì¶”ê°€
  # ì˜ˆ: JSON íŒŒì‹±, í•„ë“œ ì¶”ê°€/ì‚­ì œ, ë°ì´í„° íƒ€ì… ë³€í™˜ ë“±
}

output {
  elasticsearch {
    hosts => ["https://es01:9200"] # Elasticsearch í´ëŸ¬ìŠ¤í„°ì˜ ëª¨ë“  ë…¸ë“œ ì§€ì •
    user => "${ELASTIC_USER}"
    password => "${ELASTIC_PASSWORD}" # .env íŒŒì¼ì˜ ELASTIC_PASSWORDë¥¼ ì°¸ì¡°í•©ë‹ˆë‹¤.
    ssl => true
    ssl_certificate_authorities => ["/usr/share/logstash/config/certs/ca/ca.crt"]
    index => "%{[@metadata][beat]}-%{[@metadata][version]}-%{+YYYY.MM.dd}" # ì¸ë±ìŠ¤ ì´ë¦„ í˜•ì‹
  }
  stdout { codec => rubydebug } # ë””ë²„ê¹…ì„ ìœ„í•´ ì½˜ì†”ì— ì¶œë ¥ (ìš´ì˜ì—ì„œëŠ” ë¹„í™œì„±í™”)
}
```

```bash
sudo mkdir -pv /data/elk/certs \
               /data/elk/es/data01 \
               /data/elk/kibana/data \
               /data/elk/logstash/data

sudo chown -R 1000:1000 /data/elk/
sudo chcon -vRt container_file_t /data/elk
sudo semanage fcontext -a -t container_file_t "/data/elk(/.*)?"
sudo restorecon -Rv /data/elk
```

```bash
version: "3.8"


volumes:

networks:
 default:
   name: elastic
   external: false


services:
  setup:
    container_name: elk-setup
    image: docker.elastic.co/elasticsearch/elasticsearch:${STACK_VERSION}
    volumes:
      - /data/elk/certs:/usr/share/elasticsearch/config/certs:Z
    user: "0"
    command: >
      bash -c '
        if [ x${ELASTIC_PASSWORD} == x ]; then
          echo "Set the ELASTIC_PASSWORD environment variable in the .env file";
          exit 1;
        elif [ x${KIBANA_PASSWORD} == x ]; then
          echo "Set the KIBANA_PASSWORD environment variable in the .env file";
          exit 1;
        fi;
        if [ ! -f config/certs/ca.zip ]; then
          echo "Creating CA";
          bin/elasticsearch-certutil ca --silent --pem -out config/certs/ca.zip;
          unzip config/certs/ca.zip -d config/certs;
        fi;
        if [ ! -f config/certs/certs.zip ]; then
          echo "Creating certs";
          echo -ne \
          "instances:\n"\
          "  - name: es01\n"\
          "    dns:\n"\
          "      - es01\n"\
          "      - localhost\n"\
          "    ip:\n"\
          "      - 127.0.0.1\n"\
          "  - name: kibana\n"\
          "    dns:\n"\
          "      - kibana\n"\
          "      - localhost\n"\
          "    ip:\n"\
          "      - 127.0.0.1\n"\
          "  - name: logstash\n"\
          "    dns:\n"\
          "      - logstash\n"\
          "      - localhost\n"\
          "    ip:\n"\
          "      - 127.0.0.1\n"\
          > config/certs/instances.yml;
          bin/elasticsearch-certutil cert --silent --pem -out config/certs/certs.zip --in config/certs/instances.yml --ca-cert config/certs/ca/ca.crt --ca-key config/certs/ca/ca.key;
          unzip config/certs/certs.zip -d config/certs;
        fi;
        echo "Setting file permissions"
        chown -R root:root config/certs;
        find . -type d -exec chmod 750 \{\} \;;
        find . -type f -exec chmod 640 \{\} \;;
        echo "Waiting for Elasticsearch availability";
        until curl -s --cacert config/certs/ca/ca.crt https://es01:9200 | grep -q "missing authentication credentials"; do sleep 30; done;
        echo "Setting kibana_system password";
        until curl -s -X POST --cacert config/certs/ca/ca.crt -u "elastic:${ELASTIC_PASSWORD}" -H "Content-Type: application/json" https://es01:9200/_security/user/kibana_system/_password -d "{\"password\":\"${KIBANA_PASSWORD}\"}" | grep -q "^{}"; do sleep 10; done;
        echo "All done!";
      '
    healthcheck:
      test: ["CMD-SHELL", "[ -f config/certs/es01/es01.crt ]"]
      interval: 1s
      timeout: 5s
      retries: 120

  # Elasticsearch ë…¸ë“œ 1
  es01:
    depends_on:
      setup:
        condition: service_healthy
    container_name: elk-es01
    image: docker.elastic.co/elasticsearch/elasticsearch:${STACK_VERSION}
    labels:
      co.elastic.logs/module: elasticsearch
    volumes:
      - /data/elk/certs:/usr/share/elasticsearch/config/certs:ro
      - /data/elk/es/data01:/usr/share/elasticsearch/data:Z
    ports:
      - 9200:9200
      - 9300:9300
    environment:
      - node.name=es01
      - cluster.name=${CLUSTER_NAME}
      - discovery.type=single-node
      - ELASTIC_PASSWORD=${ELASTIC_PASSWORD}
      - bootstrap.memory_lock=true
      - xpack.security.enabled=true
      - xpack.security.http.ssl.enabled=true
      - xpack.security.http.ssl.key=certs/es01/es01.key
      - xpack.security.http.ssl.certificate=certs/es01/es01.crt
      - xpack.security.http.ssl.certificate_authorities=certs/ca/ca.crt
      - xpack.security.transport.ssl.enabled=true
      - xpack.security.transport.ssl.key=certs/es01/es01.key
      - xpack.security.transport.ssl.certificate=certs/es01/es01.crt
      - xpack.security.transport.ssl.certificate_authorities=certs/ca/ca.crt
      - xpack.security.transport.ssl.verification_mode=certificate
      - xpack.license.self_generated.type=${LICENSE}
      - ES_JAVA_OPTS=${ES_JAVA_OPTS}
    mem_limit: ${ES_MEM_LIMIT}
    ulimits:
      memlock:
        soft: -1
        hard: -1
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "curl -s --cacert config/certs/ca/ca.crt https://localhost:9200 | grep -q 'missing authentication credentials'",
        ]
      interval: 10s
      timeout: 10s
      retries: 120

  # kibana ë…¸ë“œ 1
  kibana:
    depends_on:
      es01:
        condition: service_healthy
    container_name: elk-kibana01
    image: docker.elastic.co/kibana/kibana:${STACK_VERSION}
    labels:
      co.elastic.logs/module: kibana
    volumes:
      - /data/elk/certs:/usr/share/kibana/config/certs:ro
      - /data/elk/kibana/data:/usr/share/kibana/data:Z
    ports:
      - ${KIBANA_PORT}:5601
    environment:
      - SERVERNAME=kibana
      - ELASTICSEARCH_HOSTS=https://es01:9200
      - ELASTICSEARCH_USERNAME=kibana_system
      - ELASTICSEARCH_PASSWORD=${KIBANA_PASSWORD}
      - ELASTICSEARCH_SSL_CERTIFICATEAUTHORITIES=config/certs/ca/ca.crt
      - XPACK_SECURITY_ENCRYPTIONKEY=${ENCRYPTION_KEY}
      - XPACK_ENCRYPTEDSAVEDOBJECTS_ENCRYPTIONKEY=${ENCRYPTION_KEY}
      - XPACK_REPORTING_ENCRYPTIONKEY=${ENCRYPTION_KEY}
    mem_limit: ${KB_MEM_LIMIT}
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "curl -s -I http://localhost:5601 | grep -q 'HTTP/1.1 302 Found'",
        ]
      interval: 10s
      timeout: 10s
      retries: 120

  # Logstash ë…¸ë“œ 1
  logstash01:
    depends_on:
      es01:
        condition: service_healthy
      kibana:
        condition: service_healthy
    container_name: elk-logstash01
    image: docker.elastic.co/logstash/logstash:${STACK_VERSION}
    labels:
      co.elastic.logs/module: logstash
    user: root
    volumes:
      - /data/elk/certs:/usr/share/logstash/config/certs:ro
      - /data/elk/logstash/data:/usr/share/logstash/data:Z
      - "./logstash.conf:/usr/share/logstash/pipeline/logstash.conf:ro"
    environment:
      - xpack.monitoring.enabled=false
      - ELASTIC_USER=elastic
      - ELASTIC_PASSWORD=${ELASTIC_PASSWORD}
      - ELASTIC_HOSTS=https://es01:9200

  # Metricbeat ë…¸ë“œ 1
  metricbeat01:
    depends_on:
      es01:
        condition: service_healthy
      kibana:
        condition: service_healthy
    container_name: elk-metricbeat01
    image: docker.elastic.co/beats/metricbeat:${STACK_VERSION}
    user: root
    volumes:
      - /data/elk/certs:/usr/share/metricbeat/certs:ro
      - /data/elk/metricbeat/data:/usr/share/metricbeat/data
      - "./metricbeat.yml:/usr/share/metricbeat/metricbeat.yml:ro"
      - "/var/run/docker.sock:/var/run/docker.sock:ro"
      - "/sys/fs/cgroup:/hostfs/sys/fs/cgroup:ro"
      - "/proc:/hostfs/proc:ro"
      - "/:/hostfs:ro"
    environment:
      - ELASTIC_USER=${ELASTIC_USER}
      - ELASTIC_PASSWORD=${ELASTIC_PASSWORD}
      - ELASTIC_HOSTS=https://es01:9200
      - KIBANA_HOSTS=http://kibana:5601
      - LOGSTASH_HOSTS=http://logstash01:9600
```

```yaml
# logstash.conf
input {
  beats {
    port => 5044
    ssl => true
    ssl_certificate_authorities => ["/usr/share/logstash/config/certs/ca/ca.crt"]
    ssl_certificate => "/usr/share/logstash/config/certs/logstash/logstash.crt" # Logstash ìì²´ ì¸ì¦ì„œ (Beatsì™€ì˜ SSL í†µì‹ ìš©)
    ssl_key => "/usr/share/logstash/config/certs/logstash/logstash.key" # Logstash ìì²´ í‚¤
    ssl_verify_mode => "peer"
  }
}

filter {
  # í•„ìš”ì— ë”°ë¼ ë°ì´í„° í•„í„°ë§ ë° ë³€í™˜ ë¡œì§ ì¶”ê°€
  # ì˜ˆ: JSON íŒŒì‹±, í•„ë“œ ì¶”ê°€/ì‚­ì œ, ë°ì´í„° íƒ€ì… ë³€í™˜ ë“±
}

output {
  elasticsearch {
    hosts => ["https://es01:9200"] # Elasticsearch í´ëŸ¬ìŠ¤í„°ì˜ ëª¨ë“  ë…¸ë“œ ì§€ì •
    user => "${ELASTIC_USER}"
    password => "${ELASTIC_PASSWORD}" # .env íŒŒì¼ì˜ ELASTIC_PASSWORDë¥¼ ì°¸ì¡°í•©ë‹ˆë‹¤.
    ssl => true
    ssl_certificate_authorities => ["/usr/share/logstash/config/certs/ca/ca.crt"]
    index => "%{[@metadata][beat]}-%{[@metadata][version]}-%{+YYYY.MM.dd}" # ì¸ë±ìŠ¤ ì´ë¦„ í˜•ì‹
  }
  stdout { codec => rubydebug } # ë””ë²„ê¹…ì„ ìœ„í•´ ì½˜ì†”ì— ì¶œë ¥ (ìš´ì˜ì—ì„œëŠ” ë¹„í™œì„±í™”)
}
```

```yaml
metricbeat.config.modules:
  path: ${path.config}/modules.d/*.yml
  reload.enabled: false


metricbeat.modules:
- module: elasticsearch
  xpack.enabled: true
  period: 10s
  hosts: ${ELASTIC_HOSTS}
  ssl.certificate_authorities: "certs/ca/ca.crt"
  ssl.certificate: "certs/es01/es01.crt"
  ssl.key: "certs/es01/es01.key"
  username: ${ELASTIC_USER}
  password: ${ELASTIC_PASSWORD}
  ssl.enabled: true


- module: logstash
  xpack.enabled: true
  period: 10s
  hosts: ${LOGSTASH_HOSTS}


- module: kibana
  metricsets:
    - stats
  period: 10s
  hosts: ${KIBANA_HOSTS}
  username: ${ELASTIC_USER}
  password: ${ELASTIC_PASSWORD}
  xpack.enabled: true


- module: docker
  metricsets:
    - "container"
    - "cpu"
    - "diskio"
    - "healthcheck"
    - "info"
    #- "image"
    - "memory"
    - "network"
  hosts: ["unix:///var/run/docker.sock"]
  period: 10s
  enabled: true


processors:
  - add_host_metadata: ~
  - add_docker_metadata: ~


output.elasticsearch:
  hosts: ${ELASTIC_HOSTS}
  username: ${ELASTIC_USER}
  password: ${ELASTIC_PASSWORD}
  ssl:
    certificate: "certs/es01/es01.crt"
    certificate_authorities: "certs/ca/ca.crt"
    key: "certs/es01/es01.key"
    verification_mode: full
```

```bash
  # Elasticsearch ë…¸ë“œ 1
  es01:
    depends_on:
      setup:
        condition: service_healthy
    container_name: elk-es01
    image: docker.elastic.co/elasticsearch/elasticsearch:${STACK_VERSION}
    labels:
      co.elastic.logs/module: elasticsearch
    volumes:
      - /data/elk/certs:/usr/share/elasticsearch/config/certs:ro
      - /data/elk/es/data01:/usr/share/elasticsearch/data:Z
    ports:
      - 9200:9200
      - 9300:9300
    environment:
      - node.name=es01
      - cluster.name=${CLUSTER_NAME}
      - discovery.seed_hosts=${ES_DISCOVERY_HOSTS}
      - cluster.initial_master_nodes=${ES_MASTER_NODES}
      - ELASTIC_PASSWORD=${ELASTIC_PASSWORD}
      - bootstrap.memory_lock=true
      - xpack.security.enabled=true
      - xpack.security.http.ssl.enabled=true
      - xpack.security.http.ssl.key=certs/es01/es01.key
      - xpack.security.http.ssl.certificate=certs/es01/es01.crt
      - xpack.security.http.ssl.certificate_authorities=certs/ca/ca.crt
      - xpack.security.transport.ssl.enabled=true
      - xpack.security.transport.ssl.key=certs/es01/es01.key
      - xpack.security.transport.ssl.certificate=certs/es01/es01.crt
      - xpack.security.transport.ssl.certificate_authorities=certs/ca/ca.crt
      - xpack.security.transport.ssl.verification_mode=certificate
      - xpack.license.self_generated.type=${LICENSE}
      - ES_JAVA_OPTS=${ES_JAVA_OPTS}
    mem_limit: ${ES_MEM_LIMIT}
    ulimits:
      memlock:
        soft: -1
        hard: -1
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "curl -s --cacert config/certs/ca/ca.crt https://localhost:9200 | grep -q 'missing authentication credentials'",
        ]
      interval: 10s
      timeout: 10s
      retries: 120
```